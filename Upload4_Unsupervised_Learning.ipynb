{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Cluster 1 Silhouette Coefficient**"
      ],
      "metadata": {
        "id": "ho7UUlOgyDer"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6x0hEBTxlcm"
      },
      "outputs": [],
      "source": [
        "import knime.scripting.io as knio\n",
        "import pandas as pd\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "# Load input table\n",
        "df = knio.input_tables[0].to_pandas()\n",
        "\n",
        "# Input Validation: Check required columns\n",
        "required_columns = ['Count*(trip time)', 'Mean(trip time)', 'Cluster']\n",
        "missing_columns = [col for col in required_columns if col not in df.columns]\n",
        "if missing_columns:\n",
        "    raise ValueError(f\"Missing required columns: {', '.join(missing_columns)}\")\n",
        "\n",
        "# Handle NaN values: Drop rows with missing data\n",
        "original_row_count = len(df)\n",
        "df = df.dropna(subset=required_columns)\n",
        "\n",
        "# Sampling to reduce dataset size if needed\n",
        "df = df.sample(n=10000, random_state=42) if len(df) > 10000 else df\n",
        "\n",
        "# Extract Features and Labels\n",
        "features = df[['Count*(trip time)', 'Mean(trip time)']]\n",
        "labels = df['Cluster']\n",
        "\n",
        "# Check if we have enough data for silhouette computation\n",
        "if len(set(labels)) < 2:\n",
        "    raise ValueError(\"Silhouette Score requires at least 2 clusters.\")\n",
        "\n",
        "# Calculate Silhouette Score with error handling\n",
        "try:\n",
        "    score = silhouette_score(features, labels)\n",
        "except Exception as e:\n",
        "    raise RuntimeError(f\"Error calculating Silhouette Score: {e}\")\n",
        "\n",
        "# Gather Cluster Metadata\n",
        "cluster_sizes = df['Cluster'].value_counts().to_dict()\n",
        "num_clusters = len(cluster_sizes)\n",
        "\n",
        "# Create Output Table\n",
        "output_df = pd.DataFrame({\n",
        "    \"Silhouette Score\": [score],\n",
        "    \"Number of Clusters\": [num_clusters],\n",
        "    \"Cluster Sizes\": [str(cluster_sizes)],\n",
        "    \"Processed Rows\": [len(df)],\n",
        "    \"Original Rows\": [original_row_count]  # Size before dropping NaNs\n",
        "})\n",
        "\n",
        "# Output the result\n",
        "knio.output_tables[0] = knio.Table.from_pandas(output_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cluster1 Python View**"
      ],
      "metadata": {
        "id": "PA9Ep4TXy1ua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import knime.scripting.io as knio\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import silhouette_samples\n",
        "import ast\n",
        "import numpy as np\n",
        "\n",
        "# Load the data from the input table\n",
        "df = knio.input_tables[0].to_pandas()\n",
        "\n",
        "# Extract relevant columns\n",
        "silhouette_scores = df[\"Silhouette Score\"]\n",
        "num_clusters = df[\"Number of Clusters\"]\n",
        "cluster_sizes = df[\"Cluster Sizes\"]\n",
        "processed_rows = df[\"Processed Rows\"]\n",
        "original_rows = df[\"Original Rows\"]\n",
        "\n",
        "# Check if 'Feature Matrix' and 'Labels' columns exist\n",
        "if 'Feature Matrix' in df.columns and 'Labels' in df.columns:\n",
        "    # Convert the 'Feature Matrix' column from string to actual matrix\n",
        "    X = np.array([ast.literal_eval(row) for row in df['Feature Matrix']])\n",
        "    labels = np.array(df['Labels'])\n",
        "\n",
        "    # Compute the silhouette scores for each sample\n",
        "    silhouette_values = silhouette_samples(X, labels)\n",
        "\n",
        "    # Create a figure and axis\n",
        "    fig, ax = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "    # Plot Silhouette Distribution per Cluster\n",
        "    y_lower = 10\n",
        "    unique_labels = np.unique(labels)\n",
        "    silhouette_avg_per_cluster = []\n",
        "    for i in unique_labels:\n",
        "        cluster_values = [v for l, v in zip(labels, silhouette_values) if l == i]\n",
        "        cluster_values.sort()\n",
        "        y_upper = y_lower + len(cluster_values)\n",
        "        ax[0, 0].fill_betweenx(range(y_lower, y_upper), 0, cluster_values, alpha=0.7)\n",
        "        ax[0, 0].text(-0.05, y_lower + 0.5 * len(cluster_values), f'Cluster {i}')\n",
        "        y_lower = y_upper + 10\n",
        "        silhouette_avg_per_cluster.append(np.mean(cluster_values))\n",
        "    ax[0, 0].set_title('Silhouette Plot for Each Cluster')\n",
        "    ax[0, 0].set_xlabel('Silhouette Coefficient')\n",
        "    ax[0, 0].set_ylabel('Cluster')\n",
        "    ax[0, 0].axvline(x=silhouette_scores.mean(), color='red', linestyle='--')\n",
        "\n",
        "    # Plot Processed Rows vs Original Rows as a bar chart\n",
        "    ax[0, 1].bar(['Processed Rows', 'Original Rows'], [processed_rows.sum(), original_rows.sum()], color='lightgreen')\n",
        "    ax[0, 1].set_title('Processed Rows vs Original Rows')\n",
        "    ax[0, 1].set_ylabel('Number of Rows')\n",
        "\n",
        "    # Plot Cluster Sizes\n",
        "    cluster_sizes_list = [list(ast.literal_eval(size).values()) for size in cluster_sizes]\n",
        "    ax[1, 0].boxplot(cluster_sizes_list)\n",
        "    ax[1, 0].set_title('Cluster Sizes')\n",
        "    ax[1, 0].set_xlabel('Clusters')\n",
        "    ax[1, 0].set_ylabel('Size')\n",
        "\n",
        "    # Plot Silhouette Distribution as a scatter plot\n",
        "    ax[1, 1].scatter(range(len(silhouette_values)), silhouette_values, c=labels, cmap='viridis', alpha=0.7)\n",
        "    ax[1, 1].set_title('Silhouette Distribution')\n",
        "    ax[1, 1].set_xlabel('Sample Index')\n",
        "    ax[1, 1].set_ylabel('Silhouette Coefficient')\n",
        "\n",
        "    # Create a new figure for the silhouette values bar chart\n",
        "    fig2, ax2 = plt.subplots(figsize=(10, 6))\n",
        "    ax2.bar(unique_labels, silhouette_avg_per_cluster, color='skyblue')\n",
        "    ax2.set_title('Average Silhouette Value per Cluster')\n",
        "    ax2.set_xlabel('Cluster')\n",
        "    ax2.set_ylabel('Average Silhouette Value')\n",
        "\n",
        "    # Adjust layout\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Assign the figures to the output_view variable\n",
        "    knio.output_view = knio.view([fig, fig2])\n",
        "else:\n",
        "    # If 'Feature Matrix' and 'Labels' columns are not present, create a simpler plot\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "    # Plot Processed Rows vs Original Rows as a bar chart\n",
        "    ax[0].bar(['Processed Rows', 'Original Rows'], [processed_rows.sum(), original_rows.sum()], color='lightgreen')\n",
        "    ax[0].set_title('Processed Rows vs Original Rows')\n",
        "    ax[0].set_ylabel('Number of Rows')\n",
        "\n",
        "    # Plot Cluster Sizes\n",
        "    cluster_sizes_list = [list(ast.literal_eval(size).values()) for size in cluster_sizes]\n",
        "    ax[1].boxplot(cluster_sizes_list)\n",
        "    ax[1].set_title('Cluster Sizes')\n",
        "    ax[1].set_xlabel('Clusters')\n",
        "    ax[1].set_ylabel('Size')\n",
        "\n",
        "    # Adjust layout\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Assign the figure to the output_view variable\n",
        "    knio.output_view = knio.view(fig)"
      ],
      "metadata": {
        "id": "0sn8OGHWy6Mx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cluster2 Silhouette Coefficient**"
      ],
      "metadata": {
        "id": "Qil8Xik6yPNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import knime.scripting.io as knio\n",
        "import pandas as pd\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "# Load input table\n",
        "df = knio.input_tables[0].to_pandas()\n",
        "\n",
        "# Input Validation: Check required columns\n",
        "required_columns = ['start_lat', 'start_lng', 'end_lat', 'end_lng', 'trip_distance_km', 'Cluster']\n",
        "missing_columns = [col for col in required_columns if col not in df.columns]\n",
        "if missing_columns:\n",
        "    raise ValueError(f\"Missing required columns: {', '.join(missing_columns)}\")\n",
        "\n",
        "# Handle NaN values: Drop rows with missing data\n",
        "original_row_count = len(df)\n",
        "df = df.dropna(subset=required_columns)\n",
        "print(f\"Dropped {original_row_count - len(df)} rows due to missing data.\")\n",
        "\n",
        "# Remove or convert geometry column\n",
        "if \"geometry\" in df.columns:\n",
        "    df = df.drop(columns=[\"geometry\"])  # Remove geometry column\n",
        "    # OR convert to string if needed:\n",
        "    # df[\"geometry\"] = df[\"geometry\"].astype(str)\n",
        "\n",
        "# Convert 'Cluster' column to integer\n",
        "df['Cluster'] = df['Cluster'].str.extract(r'(\\d+)$').astype(int)\n",
        "\n",
        "# Sampling to reduce dataset size if needed\n",
        "if len(df) > 10000:\n",
        "    df = df.sample(n=10000, random_state=42)\n",
        "    print(\"Sampling applied: Dataset reduced to 10,000 rows.\")\n",
        "else:\n",
        "    print(f\"No sampling needed: {len(df)} rows retained.\")\n",
        "\n",
        "# Extract Features and Labels\n",
        "features = df[['start_lat', 'start_lng', 'end_lat', 'end_lng', 'trip_distance_km']]\n",
        "labels = df['Cluster']\n",
        "\n",
        "# Check if we have enough data for silhouette computation\n",
        "unique_clusters = set(labels)\n",
        "if len(unique_clusters) < 2:\n",
        "    raise ValueError(f\"Silhouette Score requires at least 2 clusters. Found clusters: {unique_clusters}\")\n",
        "\n",
        "# Debugging: Log cluster sizes\n",
        "print(f\"Cluster sizes: {df['Cluster'].value_counts().to_dict()}\")\n",
        "\n",
        "# Calculate Silhouette Score with error handling\n",
        "try:\n",
        "    score = silhouette_score(features, labels)\n",
        "    print(f\"Silhouette Score calculated: {score}\")\n",
        "except Exception as e:\n",
        "    raise RuntimeError(f\"Error calculating Silhouette Score: {e}\")\n",
        "\n",
        "# Gather Cluster Metadata\n",
        "cluster_sizes = df['Cluster'].value_counts().to_dict()\n",
        "num_clusters = len(cluster_sizes)\n",
        "\n",
        "# Create Output Table\n",
        "output_df = pd.DataFrame({\n",
        "    \"Silhouette Score\": [score],\n",
        "    \"Number of Clusters\": [num_clusters],\n",
        "    \"Cluster Sizes\": [str(cluster_sizes)],\n",
        "    \"Processed Rows\": [len(df)],\n",
        "    \"Original Rows\": [original_row_count]  # Size before dropping NaNs\n",
        "})\n",
        "\n",
        "# Output the result\n",
        "knio.output_tables[0] = knio.Table.from_pandas(output_df)\n",
        "\n",
        "# Print the output dataframe for debugging purposes\n",
        "print(output_df.to_string(index=False))\n"
      ],
      "metadata": {
        "id": "3YQuRe5nyiH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cluster2 Python View**"
      ],
      "metadata": {
        "id": "i2Gl2T2ty8kH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import knime.scripting.io as knio\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import ast\n",
        "\n",
        "# Load input table\n",
        "df = knio.input_tables[0].to_pandas()\n",
        "\n",
        "# Input Validation: Check required columns\n",
        "required_columns = ['Silhouette Score', 'Number of Clusters', 'Cluster Sizes', 'Processed Rows', 'Original Rows']\n",
        "missing_columns = [col for col in required_columns if col not in df.columns]\n",
        "if missing_columns:\n",
        "    raise ValueError(f\"Missing required columns: {', '.join(missing_columns)}\")\n",
        "\n",
        "# Handle NaN values: Drop rows with missing data\n",
        "original_row_count = len(df)\n",
        "df = df.dropna(subset=required_columns)\n",
        "print(f\"Dropped {original_row_count - len(df)} rows due to missing data.\")\n",
        "\n",
        "# Convert 'Cluster Sizes' column to a dictionary\n",
        "df['Cluster Sizes'] = df['Cluster Sizes'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
        "\n",
        "# Extract key metrics\n",
        "silhouette_score = df['Silhouette Score'].iloc[0]\n",
        "num_clusters = df['Number of Clusters'].iloc[0]\n",
        "cluster_sizes = df['Cluster Sizes'].iloc[0]\n",
        "processed_rows = df['Processed Rows'].iloc[0]\n",
        "original_rows = df['Original Rows'].iloc[0]\n",
        "\n",
        "# Create Output Table\n",
        "output_df = pd.DataFrame({\n",
        "    \"Silhouette Score\": [silhouette_score],\n",
        "    \"Number of Clusters\": [num_clusters],\n",
        "    \"Cluster Sizes\": [str(cluster_sizes)],\n",
        "    \"Processed Rows\": [processed_rows],\n",
        "    \"Original Rows\": [original_rows]\n",
        "})\n",
        "\n",
        "# Visualization: Plotting\n",
        "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "# Silhouette Score as Horizontal Bar Chart\n",
        "ax[0].barh(['Silhouette Score'], [silhouette_score], color='skyblue')\n",
        "ax[0].set_xlim(-1, 1)  # Silhouette Score range is [-1, 1]\n",
        "ax[0].set_title('Silhouette Score')\n",
        "ax[0].set_xlabel('Score')\n",
        "ax[0].grid(axis='x', linestyle='--', alpha=0.7)\n",
        "\n",
        "# Cluster Sizes Plot\n",
        "cluster_labels = list(cluster_sizes.keys())\n",
        "cluster_values = list(cluster_sizes.values())\n",
        "ax[1].bar(cluster_labels, cluster_values, color='orange')\n",
        "ax[1].set_title('Cluster Sizes')\n",
        "ax[1].set_xlabel('Clusters')\n",
        "ax[1].set_ylabel('Number of Points')\n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout()\n",
        "\n",
        "# Assign the output table and view\n",
        "knio.output_tables = [knio.Table.from_pandas(output_df)]\n",
        "knio.output_view = knio.view(fig)\n"
      ],
      "metadata": {
        "id": "5ThxENb2y__q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Self Organizing Maps**"
      ],
      "metadata": {
        "id": "dNLckaoHzoJ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import knime.scripting.io as knio\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Load and preprocess the combined cluster dataset\n",
        "df = knio.input_tables[0].to_pandas()\n",
        "features = ['Count*(trip time)', 'Mean(trip time)', 'start_lat', 'start_lng', 'end_lat', 'end_lng', 'trip_distance_km']\n",
        "\n",
        "# Ensure numeric data for clustering\n",
        "data = df[features].to_numpy()\n",
        "data = (data - data.min(axis=0)) / (data.max(axis=0) - data.min(axis=0))  # Normalize data\n",
        "\n",
        "# Initialize and train the KMeans\n",
        "kmeans = KMeans(n_clusters=10, random_state=0, n_init=10)\n",
        "df['Cluster'] = kmeans.fit_predict(data)\n",
        "\n",
        "# Visualize the KMeans clusters\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.scatterplot(x='start_lat', y='start_lng', hue='Cluster', data=df, palette='viridis')\n",
        "plt.title(\"KMeans Cluster Visualization\")\n",
        "plt.xlabel(\"Start Latitude\")\n",
        "plt.ylabel(\"Start Longitude\")\n",
        "plt.savefig(\"kmeans_cluster_visualization.png\")  # Save the plot instead of showing it\n",
        "\n",
        "# Analyze cluster assignments\n",
        "cluster_assignments = df.groupby('Cluster').mean(numeric_only=True)\n",
        "\n",
        "# Save results if needed\n",
        "if \"geometry\" in df.columns:\n",
        "    df = df.drop(columns=[\"geometry\"])  # Remove geometry column\n",
        "\n",
        "# Save CSV files in KNIME workspace\n",
        "workspace_path = knio.flow_variables[\"knime.workspace\"]\n",
        "output_csv_path = f\"{workspace_path}/kmeans_clustered_results.csv\"\n",
        "cluster_summary_output_path = f\"{workspace_path}/cluster_summary.csv\"\n",
        "\n",
        "df.to_csv(output_csv_path, index=False)\n",
        "cluster_assignments.to_csv(cluster_summary_output_path, index=True)\n",
        "\n",
        "# Output the modified dataframe\n",
        "knio.output_tables[0] = knio.Table.from_pandas(df)\n",
        "\n",
        "# Debugging: Print the cluster assignments\n",
        "print(cluster_assignments)\n",
        "\n"
      ],
      "metadata": {
        "id": "ELZLmSOkzvO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Combined Visualizations Python View**"
      ],
      "metadata": {
        "id": "sCcwdJDAz0u3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import knime.scripting.io as knio\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load the cluster summary dataframe\n",
        "df = knio.input_tables[0].to_pandas()\n",
        "\n",
        "# Create subplots for visualizations\n",
        "fig, ax = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "# Plot 1: Cluster Characteristics (Bar Plot)\n",
        "metrics = ['Count*(trip time)', 'Mean(trip time)']\n",
        "df[metrics].plot(kind='bar', ax=ax[0, 0], color=['skyblue', 'orange'])\n",
        "ax[0, 0].set_title('Cluster Characteristics')\n",
        "ax[0, 0].set_xlabel('Clusters')\n",
        "ax[0, 0].set_ylabel('Values')\n",
        "ax[0, 0].legend(loc='upper left')\n",
        "\n",
        "# Plot 2: Cluster Locations (Scatter Plot)\n",
        "sns.scatterplot(\n",
        "    data=df, x='lon', y='lat', hue='Cluster', palette='viridis', s=100, ax=ax[0, 1]\n",
        ")\n",
        "ax[0, 1].set_title('Cluster Locations')\n",
        "ax[0, 1].set_xlabel('Longitude')\n",
        "ax[0, 1].set_ylabel('Latitude')\n",
        "ax[0, 1].legend(title='Cluster', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "\n",
        "# Plot 3: Outlier Detection (Boxplot for `Count*(trip time)`)\n",
        "sns.boxplot(data=df[['Count*(trip time)']], ax=ax[1, 0], palette='pastel')\n",
        "ax[1, 0].set_title('Outlier Detection: Count*(trip time)')\n",
        "ax[1, 0].set_ylabel('Count*(trip time)')\n",
        "\n",
        "# Plot 4: Outlier Detection (Boxplot for `Mean(trip time)`)\n",
        "sns.boxplot(data=df[['Mean(trip time)']], ax=ax[1, 1], palette='muted')\n",
        "ax[1, 1].set_title('Outlier Detection: Mean(trip time)')\n",
        "ax[1, 1].set_ylabel('Mean(trip time)')\n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout()\n",
        "\n",
        "# Assign the figure to the output view\n",
        "knio.output_view = knio.view(fig)"
      ],
      "metadata": {
        "id": "_8Yli-5k0DZw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}